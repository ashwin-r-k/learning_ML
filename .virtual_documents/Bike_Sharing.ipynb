import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 

from imblearn.over_sampling import RandomOverSampler
from sklearn.preprocessing import StandardScaler

import copy 
import tensorflow as tf 
from sklearn.linear_model import LinearRegression






dataset_cols = ["bike_count", "hour", "temp", "humidity", "wind", "visibility", "dew_pt_temp", "radiation", "rain", "snow", "functional"]



df = pd.read_csv("SeoulBikeData.csv", encoding='unicode_escape').drop(["Date", "Holiday", "Seasons"], axis=1)


df.columns = dataset_cols
df.head()
df["functional"] = (df['functional'] == "yes").astype("int")


df.head()


df = df[df["hour" ]== 12]  # Simplifing model iat noon only


df


for label in df.columns[1:]:
    plt.scatter(df[label],df["bike_count"])
    plt.title(label)
    plt.xlabel(label)
    plt.ylabel("Bike count at noon")
    plt.show()


df.hist(bins=70,figsize=(20,15))


df = df.drop(["wind","visibility","functional"],axis=1)



#Train Validation and Test

train, val, test = np.split( df.sample(frac=1), [ int(0.6*len(df)) , int(0.8*len(df)) ])



def get_xy(df, y_label,x_label=None):
    df = copy.deepcopy(df)
    if not x_label:
        X = df[ [c for c in df.columns if c!=y_label]].values
    else:
        if len(x_label)==1:
            X=df[x_label[0]].values.reshape(-1,1)
        else:
            X = df[x_label].values
    y = df[y_label].values.reshape(-1,1)
    data = np.hstack((X,y))

    return data,X,y


_, x_train_temp, y_train_temp = get_xy(train,"bike_count",x_label=["temp"])
_, x_val_temp, y_val_temp = get_xy(val,"bike_count",x_label=["temp"])
_, x_test_temp, y_test_temp = get_xy(test,"bike_count",x_label=["temp"])


temp_reg = LinearRegression()


temp_reg.fit(x_train_temp,y_train_temp)


temp_reg.score(x_test_temp,y_test_temp)


plt.scatter(x_train_temp,y_train_temp,label = "train data", color = "blue")

x = tf.linspace(-20,40,100)
plt.plot(x,temp_reg.predict(np.array(x).reshape(-1,1)), label= "FIT" , color="red" )
plt.legend()
plt.title("Bikes vs Temp")
plt.ylabel("no of bikes")
plt.xlabel("temp")
plt.show()


print(x)


print(np.array(x).reshape(-1,1))





def get_xy(df, y_label,x_label=None):
    df = copy.deepcopy(df)
    if x_label is None:
        X = df[ [c for c in df.columns if c!=y_label]].values
    else:
        if len(x_label)==1:
            X=df[x_label[0]].values.reshape(-1,1)
        else:
            X = df[x_label].values
    y = df[y_label].values.reshape(-1,1)
    data = np.hstack((X,y))

    return data,X,y


_, x_train_all, y_train_all = get_xy(train,"bike_count",x_label=df.columns[1:])
_, x_val_all, y_val_all = get_xy(val,"bike_count",x_label=df.columns[1:])
_, x_test_all, y_test_all = get_xy(test,"bike_count",x_label=df.columns[1:])


all_reg = LinearRegression()
all_reg.fit(x_train_all,y_train_all)


all_reg.score(x_test_all,y_test_all)





temp_normalizer = tf.keras.layers.Normalization(input_shape=(1,1) , axis=None)
temp_normalizer.adapt(x_train_temp.reshape(-1,1))


temp_nn_model = tf.keras.Sequential(
    [temp_normalizer,
    tf.keras.layers.Dense(1)
    ])


temp_nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='mean_squared_error')


history = temp_nn_model.fit(
    x_train_temp.reshape(-1,1),y_train_temp,
    verbose=0,
    epochs=1000,
    validation_data=(x_val_temp,y_val_temp)
)


def plot_loss(hist):
    plt.plot(hist.history["loss"] ,label = "loss", color = "blue")
    plt.plot(hist.history["val_loss"] ,label = "val_loss", color = "red")

    plt.legend()
    plt.title("Bikes vs Temp")
    plt.ylabel("MSE")
    plt.xlabel("Epoch")
    plt.grid(True)
    plt.show()


plot_loss(history)


plt.scatter(x_train_temp,y_train_temp,label = "train data", color = "blue")

x = tf.linspace(-20,40,100)
plt.plot(x, temp_nn_model.predict(np.array(x).reshape(-1,1)), label="Fit", color="red", linewidth=3)

plt.title("Bikes vs Temp")
plt.ylabel("no of bikes")
plt.xlabel("temp")
plt.legend()
plt.show()





temp_normalizer = tf.keras.layers.Normalization(input_shape=(1,) , axis=None)
temp_normalizer.adapt(x_train_temp.reshape(-1,))

temp_nn_model_multilayer = tf.keras.Sequential(
    
    [temp_normalizer,
     tf.keras.layers.Dense(32, activation = "relu"),
     tf.keras.layers.Dense(32, activation = "relu"),
     tf.keras.layers.Dropout(0.1),
     tf.keras.layers.Dense(16, activation = "relu"),
    tf.keras.layers.Dense(1)
    ])
temp_nn_model_multilayer.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error' )


history = temp_nn_model_multilayer.fit(x_train_temp,y_train_temp,validation_data=(x_val_temp,y_val_temp),epochs=100,verbose=0)


plot_loss(history)


plt.scatter(x_train_temp, y_train_temp, label="Data", color="blue")
x = tf.linspace(-20, 40, 100)

plt.plot(x,temp_nn_model_multilayer(np.array(x).reshape(-1,1)), label="Fit", color="red", linewidth=3 )
plt.legend()
plt.title("Bikes vs Temp")
plt.ylabel("Number of bikes")
plt.xlabel("Temp")
plt.show()





all_normalizer = tf.keras.layers.Normalization(input_shape=(7,), axis=-1)
all_normalizer.adapt(x_train_all)


nn_model = tf.keras.Sequential([
    all_normalizer,
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(1)
])

nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')


history = nn_model.fit(
    x_train_all, y_train_all,
    validation_data=(x_val_all, y_val_all),
    verbose=0, epochs=100
)


plot_loss(history)


# calculate the MSE for both linear reg and nn
y_pred_lr = all_reg.predict(x_test_all)
y_pred_nn = nn_model.predict(x_test_all)

def MSE(y_pred, y_real):
  return (np.square(y_pred - y_real)).mean()


MSE(y_pred_lr, y_test_all)


MSE(y_pred_nn, y_test_all)


plt.axes(aspect="equal")
plt.scatter(y_test_all,y_pred_lr, label="linear regration pred")
plt.scatter(y_test_all,y_pred_nn, label="NN pred")

plt.xlabel('true values')
plt.plot("Predictions")
plt.grid(True)

lims = [0,1800]
plt.xlim(lims)
plt.ylim(lims)
plt.plot(lims,lims,"--r")
plt.show()



